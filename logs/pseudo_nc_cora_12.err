INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:Num classes: 7
INFO:root:NCModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(in_features=1434, out_features=16, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (agg): HypAgg(c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (hyp_act): HypAct(c_in=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>), c_out=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
      )
    )
  )
  (decoder): LinearDecoder(
    in_features=16, out_features=7, bias=1, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>)
    (cls): Linear(
      (linear): Linear(in_features=16, out_features=7, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 23079
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.9516 train_acc: 0.1786 train_f1: 0.1786 time: 1.1225s
INFO:root:Epoch: 0005 val_loss: 1.9363 val_acc: 0.1300 val_f1: 0.1300
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.9179 train_acc: 0.1857 train_f1: 0.1857 time: 0.9619s
INFO:root:Epoch: 0010 val_loss: 1.9366 val_acc: 0.1580 val_f1: 0.1580
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.8866 train_acc: 0.3429 train_f1: 0.3429 time: 1.1178s
INFO:root:Epoch: 0015 val_loss: 1.9273 val_acc: 0.2640 val_f1: 0.2640
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.8635 train_acc: 0.3071 train_f1: 0.3071 time: 1.0370s
INFO:root:Epoch: 0020 val_loss: 1.8963 val_acc: 0.3880 val_f1: 0.3880
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.8141 train_acc: 0.4500 train_f1: 0.4500 time: 1.1192s
INFO:root:Epoch: 0025 val_loss: 1.8616 val_acc: 0.5220 val_f1: 0.5220
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 1.7636 train_acc: 0.4786 train_f1: 0.4786 time: 0.9236s
INFO:root:Epoch: 0030 val_loss: 1.8386 val_acc: 0.5480 val_f1: 0.5480
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 1.6797 train_acc: 0.5357 train_f1: 0.5357 time: 1.1165s
INFO:root:Epoch: 0035 val_loss: 1.8036 val_acc: 0.5560 val_f1: 0.5560
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 1.5798 train_acc: 0.6500 train_f1: 0.6500 time: 1.0086s
INFO:root:Epoch: 0040 val_loss: 1.7527 val_acc: 0.6280 val_f1: 0.6280
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 1.5763 train_acc: 0.5500 train_f1: 0.5500 time: 1.1252s
INFO:root:Epoch: 0045 val_loss: 1.7063 val_acc: 0.6460 val_f1: 0.6460
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 1.4761 train_acc: 0.5643 train_f1: 0.5643 time: 1.0133s
INFO:root:Epoch: 0050 val_loss: 1.6786 val_acc: 0.6180 val_f1: 0.6180
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 1.3532 train_acc: 0.6357 train_f1: 0.6357 time: 1.1199s
INFO:root:Epoch: 0055 val_loss: 1.6268 val_acc: 0.6800 val_f1: 0.6800
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 1.3805 train_acc: 0.5786 train_f1: 0.5786 time: 1.0265s
INFO:root:Epoch: 0060 val_loss: 1.5586 val_acc: 0.7400 val_f1: 0.7400
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 1.2889 train_acc: 0.5929 train_f1: 0.5929 time: 1.1106s
INFO:root:Epoch: 0065 val_loss: 1.5171 val_acc: 0.7460 val_f1: 0.7460
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 1.2935 train_acc: 0.5286 train_f1: 0.5286 time: 0.9238s
INFO:root:Epoch: 0070 val_loss: 1.4897 val_acc: 0.7440 val_f1: 0.7440
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 1.2479 train_acc: 0.5857 train_f1: 0.5857 time: 1.1136s
INFO:root:Epoch: 0075 val_loss: 1.4433 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 1.1424 train_acc: 0.5786 train_f1: 0.5786 time: 0.9865s
INFO:root:Epoch: 0080 val_loss: 1.4106 val_acc: 0.7400 val_f1: 0.7400
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 1.1386 train_acc: 0.6071 train_f1: 0.6071 time: 1.1298s
INFO:root:Epoch: 0085 val_loss: 1.3844 val_acc: 0.7240 val_f1: 0.7240
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 1.1123 train_acc: 0.6143 train_f1: 0.6143 time: 0.9973s
INFO:root:Epoch: 0090 val_loss: 1.3358 val_acc: 0.7340 val_f1: 0.7340
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 1.0254 train_acc: 0.6714 train_f1: 0.6714 time: 1.1019s
INFO:root:Epoch: 0095 val_loss: 1.3024 val_acc: 0.7500 val_f1: 0.7500
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.9515 train_acc: 0.6429 train_f1: 0.6429 time: 1.1357s
INFO:root:Epoch: 0100 val_loss: 1.2677 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.8533 train_acc: 0.6571 train_f1: 0.6571 time: 1.0027s
INFO:root:Epoch: 0105 val_loss: 1.2436 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.9778 train_acc: 0.6429 train_f1: 0.6429 time: 1.2752s
INFO:root:Epoch: 0110 val_loss: 1.2207 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 1.0519 train_acc: 0.5786 train_f1: 0.5786 time: 1.1978s
INFO:root:Epoch: 0115 val_loss: 1.1941 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 1.0126 train_acc: 0.5786 train_f1: 0.5786 time: 1.0112s
INFO:root:Epoch: 0120 val_loss: 1.1711 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.9261 train_acc: 0.6571 train_f1: 0.6571 time: 1.2581s
INFO:root:Epoch: 0125 val_loss: 1.1498 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.7963 train_acc: 0.6643 train_f1: 0.6643 time: 1.2946s
INFO:root:Epoch: 0130 val_loss: 1.1197 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.9218 train_acc: 0.6071 train_f1: 0.6071 time: 0.9879s
INFO:root:Epoch: 0135 val_loss: 1.1235 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.7406 train_acc: 0.6929 train_f1: 0.6929 time: 0.9993s
INFO:root:Epoch: 0140 val_loss: 1.1189 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.8516 train_acc: 0.6571 train_f1: 0.6571 time: 1.1291s
INFO:root:Epoch: 0145 val_loss: 1.0929 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.9077 train_acc: 0.6000 train_f1: 0.6000 time: 1.1991s
INFO:root:Epoch: 0150 val_loss: 1.0663 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.7730 train_acc: 0.6643 train_f1: 0.6643 time: 1.0116s
INFO:root:Epoch: 0155 val_loss: 1.0522 val_acc: 0.7680 val_f1: 0.7680
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.7783 train_acc: 0.6786 train_f1: 0.6786 time: 1.2776s
INFO:root:Epoch: 0160 val_loss: 1.0510 val_acc: 0.7740 val_f1: 0.7740
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.8407 train_acc: 0.6429 train_f1: 0.6429 time: 1.2959s
INFO:root:Epoch: 0165 val_loss: 1.0543 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.8117 train_acc: 0.6786 train_f1: 0.6786 time: 1.1828s
INFO:root:Epoch: 0170 val_loss: 1.0386 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.7918 train_acc: 0.6214 train_f1: 0.6214 time: 1.1705s
INFO:root:Epoch: 0175 val_loss: 1.0238 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.9019 train_acc: 0.5929 train_f1: 0.5929 time: 1.1607s
INFO:root:Epoch: 0180 val_loss: 1.0226 val_acc: 0.7500 val_f1: 0.7500
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.6813 train_acc: 0.7000 train_f1: 0.7000 time: 1.2907s
INFO:root:Epoch: 0185 val_loss: 1.0146 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.7534 train_acc: 0.6571 train_f1: 0.6571 time: 1.1254s
INFO:root:Epoch: 0190 val_loss: 0.9924 val_acc: 0.7560 val_f1: 0.7560
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.6994 train_acc: 0.7071 train_f1: 0.7071 time: 1.1954s
INFO:root:Epoch: 0195 val_loss: 0.9847 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.8223 train_acc: 0.6000 train_f1: 0.6000 time: 1.0808s
INFO:root:Epoch: 0200 val_loss: 0.9777 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.7436 train_acc: 0.7071 train_f1: 0.7071 time: 1.1706s
INFO:root:Epoch: 0205 val_loss: 0.9877 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.6967 train_acc: 0.6786 train_f1: 0.6786 time: 1.1120s
INFO:root:Epoch: 0210 val_loss: 0.9972 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.7827 train_acc: 0.6571 train_f1: 0.6571 time: 1.2917s
INFO:root:Epoch: 0215 val_loss: 0.9912 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.6963 train_acc: 0.6929 train_f1: 0.6929 time: 1.1818s
INFO:root:Epoch: 0220 val_loss: 0.9838 val_acc: 0.7440 val_f1: 0.7440
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.7883 train_acc: 0.6500 train_f1: 0.6500 time: 1.1085s
INFO:root:Epoch: 0225 val_loss: 0.9561 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 323.9725s
INFO:root:Val set results: val_loss: 1.1215 val_acc: 0.7740 val_f1: 0.7740
INFO:root:Test set results: test_loss: 1.0971 test_acc: 0.7760 test_f1: 0.7760
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/nc/2021_4_22/13
