INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:Num classes: 7
INFO:root:NCModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(in_features=1434, out_features=16, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (agg): HypAgg(c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (hyp_act): HypAct(c_in=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>), c_out=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
      )
    )
  )
  (decoder): LinearDecoder(
    in_features=16, out_features=7, bias=1, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>)
    (cls): Linear(
      (linear): Linear(in_features=16, out_features=7, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 23079
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.9518 train_acc: 0.1786 train_f1: 0.1786 time: 1.1413s
INFO:root:Epoch: 0005 val_loss: 1.9366 val_acc: 0.1300 val_f1: 0.1300
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.9185 train_acc: 0.1857 train_f1: 0.1857 time: 0.9964s
INFO:root:Epoch: 0010 val_loss: 1.9373 val_acc: 0.1580 val_f1: 0.1580
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.8873 train_acc: 0.3357 train_f1: 0.3357 time: 1.0807s
INFO:root:Epoch: 0015 val_loss: 1.9299 val_acc: 0.2280 val_f1: 0.2280
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.8639 train_acc: 0.2929 train_f1: 0.2929 time: 1.1601s
INFO:root:Epoch: 0020 val_loss: 1.9005 val_acc: 0.3740 val_f1: 0.3740
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.8139 train_acc: 0.4429 train_f1: 0.4429 time: 0.9908s
INFO:root:Epoch: 0025 val_loss: 1.8604 val_acc: 0.5200 val_f1: 0.5200
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 1.7600 train_acc: 0.4786 train_f1: 0.4786 time: 1.0863s
INFO:root:Epoch: 0030 val_loss: 1.8356 val_acc: 0.5440 val_f1: 0.5440
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 1.6725 train_acc: 0.5357 train_f1: 0.5357 time: 1.1116s
INFO:root:Epoch: 0035 val_loss: 1.8065 val_acc: 0.5080 val_f1: 0.5080
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 1.5641 train_acc: 0.6500 train_f1: 0.6500 time: 1.0099s
INFO:root:Epoch: 0040 val_loss: 1.7524 val_acc: 0.6040 val_f1: 0.6040
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 1.5558 train_acc: 0.5500 train_f1: 0.5500 time: 1.1145s
INFO:root:Epoch: 0045 val_loss: 1.6978 val_acc: 0.6380 val_f1: 0.6380
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 1.4452 train_acc: 0.5786 train_f1: 0.5786 time: 1.0207s
INFO:root:Epoch: 0050 val_loss: 1.6677 val_acc: 0.6100 val_f1: 0.6100
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 1.3134 train_acc: 0.6286 train_f1: 0.6286 time: 1.0291s
INFO:root:Epoch: 0055 val_loss: 1.6103 val_acc: 0.6980 val_f1: 0.6980
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 1.3395 train_acc: 0.5929 train_f1: 0.5929 time: 1.1456s
INFO:root:Epoch: 0060 val_loss: 1.5359 val_acc: 0.7500 val_f1: 0.7500
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 1.2390 train_acc: 0.6143 train_f1: 0.6143 time: 1.0233s
INFO:root:Epoch: 0065 val_loss: 1.4927 val_acc: 0.7420 val_f1: 0.7420
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 1.2480 train_acc: 0.5357 train_f1: 0.5357 time: 1.0186s
INFO:root:Epoch: 0070 val_loss: 1.4594 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 1.1904 train_acc: 0.6071 train_f1: 0.6071 time: 1.1173s
INFO:root:Epoch: 0075 val_loss: 1.4081 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 1.0919 train_acc: 0.6000 train_f1: 0.6000 time: 1.0801s
INFO:root:Epoch: 0080 val_loss: 1.3727 val_acc: 0.7520 val_f1: 0.7520
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 1.0792 train_acc: 0.6071 train_f1: 0.6071 time: 1.0304s
INFO:root:Epoch: 0085 val_loss: 1.3458 val_acc: 0.7280 val_f1: 0.7280
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 1.0560 train_acc: 0.6214 train_f1: 0.6214 time: 1.1268s
INFO:root:Epoch: 0090 val_loss: 1.2924 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 0.9765 train_acc: 0.6714 train_f1: 0.6714 time: 0.9838s
INFO:root:Epoch: 0095 val_loss: 1.2587 val_acc: 0.7560 val_f1: 0.7560
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.8966 train_acc: 0.6429 train_f1: 0.6429 time: 1.0341s
INFO:root:Epoch: 0100 val_loss: 1.2231 val_acc: 0.7460 val_f1: 0.7460
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.7997 train_acc: 0.6571 train_f1: 0.6571 time: 1.2567s
INFO:root:Epoch: 0105 val_loss: 1.1958 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.9233 train_acc: 0.6500 train_f1: 0.6500 time: 1.1227s
INFO:root:Epoch: 0110 val_loss: 1.1683 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 0.9981 train_acc: 0.5786 train_f1: 0.5786 time: 0.9264s
INFO:root:Epoch: 0115 val_loss: 1.1447 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.9705 train_acc: 0.5786 train_f1: 0.5786 time: 1.0361s
INFO:root:Epoch: 0120 val_loss: 1.1284 val_acc: 0.7560 val_f1: 0.7560
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.8819 train_acc: 0.6500 train_f1: 0.6500 time: 1.0742s
INFO:root:Epoch: 0125 val_loss: 1.1159 val_acc: 0.7520 val_f1: 0.7520
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.7578 train_acc: 0.6714 train_f1: 0.6714 time: 1.2826s
INFO:root:Epoch: 0130 val_loss: 1.0890 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.8901 train_acc: 0.6143 train_f1: 0.6143 time: 1.2908s
INFO:root:Epoch: 0135 val_loss: 1.0810 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.7042 train_acc: 0.6929 train_f1: 0.6929 time: 1.2835s
INFO:root:Epoch: 0140 val_loss: 1.0745 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.8187 train_acc: 0.6786 train_f1: 0.6786 time: 0.9948s
INFO:root:Epoch: 0145 val_loss: 1.0538 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.8778 train_acc: 0.6000 train_f1: 0.6000 time: 1.2126s
INFO:root:Epoch: 0150 val_loss: 1.0367 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.7487 train_acc: 0.6643 train_f1: 0.6643 time: 1.2662s
INFO:root:Epoch: 0155 val_loss: 1.0292 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.7502 train_acc: 0.6786 train_f1: 0.6786 time: 1.1243s
INFO:root:Epoch: 0160 val_loss: 1.0300 val_acc: 0.7720 val_f1: 0.7720
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.8155 train_acc: 0.6429 train_f1: 0.6429 time: 1.1882s
INFO:root:Epoch: 0165 val_loss: 1.0262 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.7982 train_acc: 0.6786 train_f1: 0.6786 time: 0.9856s
INFO:root:Epoch: 0170 val_loss: 1.0077 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.7713 train_acc: 0.6214 train_f1: 0.6214 time: 1.2161s
INFO:root:Epoch: 0175 val_loss: 0.9996 val_acc: 0.7560 val_f1: 0.7560
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.8842 train_acc: 0.5929 train_f1: 0.5929 time: 1.0980s
INFO:root:Epoch: 0180 val_loss: 1.0033 val_acc: 0.7520 val_f1: 0.7520
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.6567 train_acc: 0.7000 train_f1: 0.7000 time: 1.2927s
INFO:root:Epoch: 0185 val_loss: 0.9938 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.7343 train_acc: 0.6571 train_f1: 0.6571 time: 1.1231s
INFO:root:Epoch: 0190 val_loss: 0.9662 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.6811 train_acc: 0.7071 train_f1: 0.7071 time: 1.0289s
INFO:root:Epoch: 0195 val_loss: 0.9557 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.8056 train_acc: 0.5929 train_f1: 0.5929 time: 1.1518s
INFO:root:Epoch: 0200 val_loss: 0.9621 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.7258 train_acc: 0.7071 train_f1: 0.7071 time: 1.1790s
INFO:root:Epoch: 0205 val_loss: 0.9754 val_acc: 0.7520 val_f1: 0.7520
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.6782 train_acc: 0.6786 train_f1: 0.6786 time: 1.1809s
INFO:root:Epoch: 0210 val_loss: 0.9639 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.7616 train_acc: 0.6571 train_f1: 0.6571 time: 1.0001s
INFO:root:Epoch: 0215 val_loss: 0.9600 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.6836 train_acc: 0.6857 train_f1: 0.6857 time: 1.2911s
INFO:root:Epoch: 0220 val_loss: 0.9773 val_acc: 0.7320 val_f1: 0.7320
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.7766 train_acc: 0.6500 train_f1: 0.6500 time: 1.2929s
INFO:root:Epoch: 0225 val_loss: 0.9323 val_acc: 0.7520 val_f1: 0.7520
INFO:root:Epoch: 0230 lr: 0.01 train_loss: 0.7971 train_acc: 0.6214 train_f1: 0.6214 time: 1.2916s
INFO:root:Epoch: 0230 val_loss: 0.9224 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0235 lr: 0.01 train_loss: 0.7795 train_acc: 0.6000 train_f1: 0.6000 time: 1.1972s
INFO:root:Epoch: 0235 val_loss: 0.9634 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0240 lr: 0.01 train_loss: 0.8390 train_acc: 0.5786 train_f1: 0.5786 time: 1.1416s
INFO:root:Epoch: 0240 val_loss: 0.9698 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0245 lr: 0.01 train_loss: 0.7677 train_acc: 0.6071 train_f1: 0.6071 time: 1.0998s
INFO:root:Epoch: 0245 val_loss: 0.9228 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0250 lr: 0.01 train_loss: 0.7408 train_acc: 0.6643 train_f1: 0.6643 time: 1.1539s
INFO:root:Epoch: 0250 val_loss: 0.9003 val_acc: 0.7680 val_f1: 0.7680
INFO:root:Epoch: 0255 lr: 0.01 train_loss: 0.7580 train_acc: 0.6143 train_f1: 0.6143 time: 1.1889s
INFO:root:Epoch: 0255 val_loss: 0.8918 val_acc: 0.7680 val_f1: 0.7680
INFO:root:Epoch: 0260 lr: 0.01 train_loss: 0.7943 train_acc: 0.6143 train_f1: 0.6143 time: 1.2212s
INFO:root:Epoch: 0260 val_loss: 0.8895 val_acc: 0.7720 val_f1: 0.7720
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 370.9153s
INFO:root:Val set results: val_loss: 1.0300 val_acc: 0.7720 val_f1: 0.7720
INFO:root:Test set results: test_loss: 1.0029 test_acc: 0.7700 test_f1: 0.7700
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/nc/2021_4_22/21
