INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:Num classes: 7
INFO:root:NCModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(in_features=1434, out_features=16, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (agg): HypAgg(c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (hyp_act): HypAct(c_in=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>), c_out=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
      )
    )
  )
  (decoder): LinearDecoder(
    in_features=16, out_features=7, bias=1, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>)
    (cls): Linear(
      (linear): Linear(in_features=16, out_features=7, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 23079
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.9516 train_acc: 0.1786 train_f1: 0.1786 time: 1.0279s
INFO:root:Epoch: 0005 val_loss: 1.9363 val_acc: 0.1300 val_f1: 0.1300
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.9178 train_acc: 0.1786 train_f1: 0.1786 time: 0.8537s
INFO:root:Epoch: 0010 val_loss: 1.9367 val_acc: 0.1580 val_f1: 0.1580
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.8867 train_acc: 0.3429 train_f1: 0.3429 time: 1.1171s
INFO:root:Epoch: 0015 val_loss: 1.9276 val_acc: 0.2520 val_f1: 0.2520
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.8634 train_acc: 0.3071 train_f1: 0.3071 time: 0.9675s
INFO:root:Epoch: 0020 val_loss: 1.8964 val_acc: 0.3800 val_f1: 0.3800
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.8140 train_acc: 0.4429 train_f1: 0.4429 time: 1.1091s
INFO:root:Epoch: 0025 val_loss: 1.8612 val_acc: 0.5280 val_f1: 0.5280
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 1.7622 train_acc: 0.4786 train_f1: 0.4786 time: 1.0196s
INFO:root:Epoch: 0030 val_loss: 1.8380 val_acc: 0.5460 val_f1: 0.5460
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 1.6780 train_acc: 0.5429 train_f1: 0.5429 time: 1.0519s
INFO:root:Epoch: 0035 val_loss: 1.8028 val_acc: 0.5520 val_f1: 0.5520
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 1.5777 train_acc: 0.6357 train_f1: 0.6357 time: 1.1163s
INFO:root:Epoch: 0040 val_loss: 1.7509 val_acc: 0.6360 val_f1: 0.6360
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 1.5718 train_acc: 0.5500 train_f1: 0.5500 time: 1.0072s
INFO:root:Epoch: 0045 val_loss: 1.7027 val_acc: 0.6540 val_f1: 0.6540
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 1.4716 train_acc: 0.5714 train_f1: 0.5714 time: 1.1219s
INFO:root:Epoch: 0050 val_loss: 1.6745 val_acc: 0.6200 val_f1: 0.6200
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 1.3420 train_acc: 0.6357 train_f1: 0.6357 time: 1.0115s
INFO:root:Epoch: 0055 val_loss: 1.6215 val_acc: 0.6840 val_f1: 0.6840
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 1.3729 train_acc: 0.5929 train_f1: 0.5929 time: 1.1099s
INFO:root:Epoch: 0060 val_loss: 1.5520 val_acc: 0.7460 val_f1: 0.7460
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 1.2801 train_acc: 0.5929 train_f1: 0.5929 time: 1.0230s
INFO:root:Epoch: 0065 val_loss: 1.5093 val_acc: 0.7360 val_f1: 0.7360
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 1.2857 train_acc: 0.5214 train_f1: 0.5214 time: 1.0077s
INFO:root:Epoch: 0070 val_loss: 1.4808 val_acc: 0.7460 val_f1: 0.7460
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 1.2348 train_acc: 0.5929 train_f1: 0.5929 time: 1.1240s
INFO:root:Epoch: 0075 val_loss: 1.4323 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 1.1291 train_acc: 0.5786 train_f1: 0.5786 time: 0.9866s
INFO:root:Epoch: 0080 val_loss: 1.3981 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 1.1252 train_acc: 0.6000 train_f1: 0.6000 time: 1.0936s
INFO:root:Epoch: 0085 val_loss: 1.3729 val_acc: 0.7220 val_f1: 0.7220
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 1.0971 train_acc: 0.6214 train_f1: 0.6214 time: 1.1251s
INFO:root:Epoch: 0090 val_loss: 1.3232 val_acc: 0.7420 val_f1: 0.7420
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 1.0135 train_acc: 0.6714 train_f1: 0.6714 time: 1.0254s
INFO:root:Epoch: 0095 val_loss: 1.2908 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.9373 train_acc: 0.6429 train_f1: 0.6429 time: 1.0669s
INFO:root:Epoch: 0100 val_loss: 1.2539 val_acc: 0.7460 val_f1: 0.7460
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.8368 train_acc: 0.6571 train_f1: 0.6571 time: 1.1208s
INFO:root:Epoch: 0105 val_loss: 1.2269 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.9648 train_acc: 0.6500 train_f1: 0.6500 time: 1.1370s
INFO:root:Epoch: 0110 val_loss: 1.2068 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 1.0379 train_acc: 0.5786 train_f1: 0.5786 time: 1.0063s
INFO:root:Epoch: 0115 val_loss: 1.1813 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.9983 train_acc: 0.5786 train_f1: 0.5786 time: 1.1185s
INFO:root:Epoch: 0120 val_loss: 1.1528 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.9138 train_acc: 0.6429 train_f1: 0.6429 time: 1.2990s
INFO:root:Epoch: 0125 val_loss: 1.1348 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.7921 train_acc: 0.6643 train_f1: 0.6643 time: 1.3036s
INFO:root:Epoch: 0130 val_loss: 1.1126 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.9139 train_acc: 0.6071 train_f1: 0.6071 time: 0.9838s
INFO:root:Epoch: 0135 val_loss: 1.1131 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.7327 train_acc: 0.6929 train_f1: 0.6929 time: 0.9207s
INFO:root:Epoch: 0140 val_loss: 1.1050 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.8441 train_acc: 0.6571 train_f1: 0.6571 time: 1.1060s
INFO:root:Epoch: 0145 val_loss: 1.0807 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.8957 train_acc: 0.5929 train_f1: 0.5929 time: 1.2989s
INFO:root:Epoch: 0150 val_loss: 1.0573 val_acc: 0.7680 val_f1: 0.7680
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.7632 train_acc: 0.6643 train_f1: 0.6643 time: 0.9921s
INFO:root:Epoch: 0155 val_loss: 1.0434 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.7726 train_acc: 0.6786 train_f1: 0.6786 time: 1.1628s
INFO:root:Epoch: 0160 val_loss: 1.0377 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.8346 train_acc: 0.6429 train_f1: 0.6429 time: 1.1807s
INFO:root:Epoch: 0165 val_loss: 1.0422 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.8105 train_acc: 0.6786 train_f1: 0.6786 time: 1.2788s
INFO:root:Epoch: 0170 val_loss: 1.0301 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.7842 train_acc: 0.6214 train_f1: 0.6214 time: 1.2960s
INFO:root:Epoch: 0175 val_loss: 1.0157 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.8959 train_acc: 0.5929 train_f1: 0.5929 time: 1.1962s
INFO:root:Epoch: 0180 val_loss: 1.0148 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.6753 train_acc: 0.7000 train_f1: 0.7000 time: 1.1529s
INFO:root:Epoch: 0185 val_loss: 1.0101 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.7531 train_acc: 0.6571 train_f1: 0.6571 time: 1.0968s
INFO:root:Epoch: 0190 val_loss: 0.9820 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.6946 train_acc: 0.7071 train_f1: 0.7071 time: 1.1513s
INFO:root:Epoch: 0195 val_loss: 0.9717 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.8187 train_acc: 0.6000 train_f1: 0.6000 time: 1.1119s
INFO:root:Epoch: 0200 val_loss: 0.9715 val_acc: 0.7680 val_f1: 0.7680
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.7400 train_acc: 0.7071 train_f1: 0.7071 time: 1.1848s
INFO:root:Epoch: 0205 val_loss: 0.9852 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.6911 train_acc: 0.6786 train_f1: 0.6786 time: 1.1994s
INFO:root:Epoch: 0210 val_loss: 0.9870 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.7788 train_acc: 0.6571 train_f1: 0.6571 time: 1.2528s
INFO:root:Epoch: 0215 val_loss: 0.9822 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.6945 train_acc: 0.6857 train_f1: 0.6857 time: 1.2496s
INFO:root:Epoch: 0220 val_loss: 0.9768 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.7877 train_acc: 0.6500 train_f1: 0.6500 time: 1.2957s
INFO:root:Epoch: 0225 val_loss: 0.9515 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0230 lr: 0.01 train_loss: 0.8087 train_acc: 0.6214 train_f1: 0.6214 time: 1.2871s
INFO:root:Epoch: 0230 val_loss: 0.9423 val_acc: 0.7680 val_f1: 0.7680
INFO:root:Epoch: 0235 lr: 0.01 train_loss: 0.7899 train_acc: 0.6000 train_f1: 0.6000 time: 1.1638s
INFO:root:Epoch: 0235 val_loss: 0.9596 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0240 lr: 0.01 train_loss: 0.8486 train_acc: 0.5786 train_f1: 0.5786 time: 0.9653s
INFO:root:Epoch: 0240 val_loss: 0.9646 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0245 lr: 0.01 train_loss: 0.7781 train_acc: 0.6071 train_f1: 0.6071 time: 1.1737s
INFO:root:Epoch: 0245 val_loss: 0.9351 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0250 lr: 0.01 train_loss: 0.7476 train_acc: 0.6643 train_f1: 0.6643 time: 1.1752s
INFO:root:Epoch: 0250 val_loss: 0.9194 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0255 lr: 0.01 train_loss: 0.7714 train_acc: 0.6143 train_f1: 0.6143 time: 1.0772s
INFO:root:Epoch: 0255 val_loss: 0.9183 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 369.6000s
INFO:root:Val set results: val_loss: 1.0363 val_acc: 0.7740 val_f1: 0.7740
INFO:root:Test set results: test_loss: 1.0103 test_acc: 0.7700 test_f1: 0.7700
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/nc/2021_4_22/14
