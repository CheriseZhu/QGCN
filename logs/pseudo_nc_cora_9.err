INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:Num classes: 7
INFO:root:NCModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(in_features=1434, out_features=16, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (agg): HypAgg(c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (hyp_act): HypAct(c_in=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>), c_out=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
      )
    )
  )
  (decoder): LinearDecoder(
    in_features=16, out_features=7, bias=1, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>)
    (cls): Linear(
      (linear): Linear(in_features=16, out_features=7, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 23079
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.9517 train_acc: 0.1857 train_f1: 0.1857 time: 0.9895s
INFO:root:Epoch: 0005 val_loss: 1.9363 val_acc: 0.1300 val_f1: 0.1300
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.9179 train_acc: 0.1857 train_f1: 0.1857 time: 1.0702s
INFO:root:Epoch: 0010 val_loss: 1.9370 val_acc: 0.1580 val_f1: 0.1580
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.8867 train_acc: 0.3357 train_f1: 0.3357 time: 1.1391s
INFO:root:Epoch: 0015 val_loss: 1.9283 val_acc: 0.2480 val_f1: 0.2480
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.8629 train_acc: 0.3071 train_f1: 0.3071 time: 1.0348s
INFO:root:Epoch: 0020 val_loss: 1.8968 val_acc: 0.3900 val_f1: 0.3900
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.8126 train_acc: 0.4357 train_f1: 0.4357 time: 1.0796s
INFO:root:Epoch: 0025 val_loss: 1.8606 val_acc: 0.5200 val_f1: 0.5200
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 1.7607 train_acc: 0.4786 train_f1: 0.4786 time: 1.1319s
INFO:root:Epoch: 0030 val_loss: 1.8375 val_acc: 0.5360 val_f1: 0.5360
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 1.6746 train_acc: 0.5286 train_f1: 0.5286 time: 0.9867s
INFO:root:Epoch: 0035 val_loss: 1.8042 val_acc: 0.5360 val_f1: 0.5360
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 1.5714 train_acc: 0.6500 train_f1: 0.6500 time: 1.0885s
INFO:root:Epoch: 0040 val_loss: 1.7509 val_acc: 0.6360 val_f1: 0.6360
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 1.5673 train_acc: 0.5500 train_f1: 0.5500 time: 1.1261s
INFO:root:Epoch: 0045 val_loss: 1.7019 val_acc: 0.6480 val_f1: 0.6480
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 1.4640 train_acc: 0.5571 train_f1: 0.5571 time: 1.0330s
INFO:root:Epoch: 0050 val_loss: 1.6732 val_acc: 0.6100 val_f1: 0.6100
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 1.3326 train_acc: 0.6286 train_f1: 0.6286 time: 1.1112s
INFO:root:Epoch: 0055 val_loss: 1.6196 val_acc: 0.6900 val_f1: 0.6900
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 1.3619 train_acc: 0.5929 train_f1: 0.5929 time: 1.0600s
INFO:root:Epoch: 0060 val_loss: 1.5510 val_acc: 0.7500 val_f1: 0.7500
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 1.2693 train_acc: 0.5929 train_f1: 0.5929 time: 1.0592s
INFO:root:Epoch: 0065 val_loss: 1.5079 val_acc: 0.7420 val_f1: 0.7420
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 1.2770 train_acc: 0.5286 train_f1: 0.5286 time: 1.1260s
INFO:root:Epoch: 0070 val_loss: 1.4786 val_acc: 0.7420 val_f1: 0.7420
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 1.2263 train_acc: 0.5929 train_f1: 0.5929 time: 0.9428s
INFO:root:Epoch: 0075 val_loss: 1.4320 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 1.1212 train_acc: 0.5786 train_f1: 0.5786 time: 1.0968s
INFO:root:Epoch: 0080 val_loss: 1.4037 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 1.1151 train_acc: 0.6000 train_f1: 0.6000 time: 1.0307s
INFO:root:Epoch: 0085 val_loss: 1.3743 val_acc: 0.7140 val_f1: 0.7140
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 1.0899 train_acc: 0.6214 train_f1: 0.6214 time: 1.0192s
INFO:root:Epoch: 0090 val_loss: 1.3199 val_acc: 0.7500 val_f1: 0.7500
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 1.0040 train_acc: 0.6714 train_f1: 0.6714 time: 0.3744s
INFO:root:Epoch: 0095 val_loss: 1.2877 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.9265 train_acc: 0.6429 train_f1: 0.6429 time: 0.4056s
INFO:root:Epoch: 0100 val_loss: 1.2587 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.8301 train_acc: 0.6571 train_f1: 0.6571 time: 0.3699s
INFO:root:Epoch: 0105 val_loss: 1.2328 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.9479 train_acc: 0.6429 train_f1: 0.6429 time: 0.4007s
INFO:root:Epoch: 0110 val_loss: 1.2017 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 1.0222 train_acc: 0.5786 train_f1: 0.5786 time: 0.9961s
INFO:root:Epoch: 0115 val_loss: 1.1712 val_acc: 0.7560 val_f1: 0.7560
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.9969 train_acc: 0.5786 train_f1: 0.5786 time: 1.1262s
INFO:root:Epoch: 0120 val_loss: 1.1558 val_acc: 0.7520 val_f1: 0.7520
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.9064 train_acc: 0.6429 train_f1: 0.6429 time: 0.9784s
INFO:root:Epoch: 0125 val_loss: 1.1370 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.7762 train_acc: 0.6714 train_f1: 0.6714 time: 1.0980s
INFO:root:Epoch: 0130 val_loss: 1.1111 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.9043 train_acc: 0.6071 train_f1: 0.6071 time: 1.0191s
INFO:root:Epoch: 0135 val_loss: 1.1058 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.7220 train_acc: 0.6857 train_f1: 0.6857 time: 1.0184s
INFO:root:Epoch: 0140 val_loss: 1.1003 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.8438 train_acc: 0.6643 train_f1: 0.6643 time: 1.1164s
INFO:root:Epoch: 0145 val_loss: 1.0797 val_acc: 0.7560 val_f1: 0.7560
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.8892 train_acc: 0.6071 train_f1: 0.6071 time: 0.9889s
INFO:root:Epoch: 0150 val_loss: 1.0563 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.7537 train_acc: 0.6643 train_f1: 0.6643 time: 1.0949s
INFO:root:Epoch: 0155 val_loss: 1.0412 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.7630 train_acc: 0.6786 train_f1: 0.6786 time: 1.1159s
INFO:root:Epoch: 0160 val_loss: 1.0371 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.8377 train_acc: 0.6429 train_f1: 0.6429 time: 1.0120s
INFO:root:Epoch: 0165 val_loss: 1.0454 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.8055 train_acc: 0.6786 train_f1: 0.6786 time: 1.1094s
INFO:root:Epoch: 0170 val_loss: 1.0332 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.7791 train_acc: 0.6214 train_f1: 0.6214 time: 1.2835s
INFO:root:Epoch: 0175 val_loss: 1.0131 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.8940 train_acc: 0.5929 train_f1: 0.5929 time: 1.0113s
INFO:root:Epoch: 0180 val_loss: 1.0084 val_acc: 0.7560 val_f1: 0.7560
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.6666 train_acc: 0.7000 train_f1: 0.7000 time: 1.1055s
INFO:root:Epoch: 0185 val_loss: 1.0071 val_acc: 0.7520 val_f1: 0.7520
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.7457 train_acc: 0.6571 train_f1: 0.6571 time: 0.8839s
INFO:root:Epoch: 0190 val_loss: 0.9820 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.6861 train_acc: 0.7071 train_f1: 0.7071 time: 1.1266s
INFO:root:Epoch: 0195 val_loss: 0.9678 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.8130 train_acc: 0.6000 train_f1: 0.6000 time: 0.9826s
INFO:root:Epoch: 0200 val_loss: 0.9647 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.7303 train_acc: 0.7071 train_f1: 0.7071 time: 1.0955s
INFO:root:Epoch: 0205 val_loss: 0.9725 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.6851 train_acc: 0.6786 train_f1: 0.6786 time: 1.1197s
INFO:root:Epoch: 0210 val_loss: 0.9773 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.7743 train_acc: 0.6571 train_f1: 0.6571 time: 0.8231s
INFO:root:Epoch: 0215 val_loss: 0.9865 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.6887 train_acc: 0.6929 train_f1: 0.6929 time: 1.0762s
INFO:root:Epoch: 0220 val_loss: 0.9889 val_acc: 0.7360 val_f1: 0.7360
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.7807 train_acc: 0.6500 train_f1: 0.6500 time: 1.2864s
INFO:root:Epoch: 0225 val_loss: 0.9432 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 300.4856s
INFO:root:Val set results: val_loss: 1.1156 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Test set results: test_loss: 1.0925 test_acc: 0.7740 test_f1: 0.7740
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/nc/2021_4_22/16
