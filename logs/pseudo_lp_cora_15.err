INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:LPModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(in_features=1434, out_features=16, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (agg): HypAgg(c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (hyp_act): HypAct(c_in=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>), c_out=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
      )
      (1): HyperbolicGraphConvolution(
        (linear): HypLinear(in_features=16, out_features=16, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (agg): HypAgg(c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (hyp_act): HypAct(c_in=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>), c_out=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
      )
    )
  )
  (dc): FermiDiracDecoder()
)
INFO:root:Total number of parameters: 23232
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 2.2440 train_roc: 0.9647 train_ap: 0.9624 time: 1.5022s
INFO:root:Epoch: 0005 val_loss: 2.2486 val_roc: 0.8062 val_ap: 0.8303
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 2.2228 train_roc: 0.9737 train_ap: 0.9726 time: 1.5345s
INFO:root:Epoch: 0010 val_loss: 2.2304 val_roc: 0.8421 val_ap: 0.8490
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 2.1759 train_roc: 0.9748 train_ap: 0.9767 time: 1.5225s
INFO:root:Epoch: 0015 val_loss: 2.1721 val_roc: 0.8495 val_ap: 0.8523
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.9308 train_roc: 0.9758 train_ap: 0.9742 time: 1.6589s
INFO:root:Epoch: 0020 val_loss: 1.9863 val_roc: 0.8517 val_ap: 0.8537
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.3858 train_roc: 0.9769 train_ap: 0.9742 time: 1.6383s
INFO:root:Epoch: 0025 val_loss: 1.5173 val_roc: 0.8526 val_ap: 0.8545
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 0.6764 train_roc: 0.9736 train_ap: 0.9714 time: 1.5848s
INFO:root:Epoch: 0030 val_loss: 1.0304 val_roc: 0.8553 val_ap: 0.8572
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 0.6081 train_roc: 0.9714 train_ap: 0.9726 time: 1.5805s
INFO:root:Epoch: 0035 val_loss: 1.4429 val_roc: 0.8604 val_ap: 0.8618
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 0.8634 train_roc: 0.9814 train_ap: 0.9795 time: 1.6061s
INFO:root:Epoch: 0040 val_loss: 1.7977 val_roc: 0.8675 val_ap: 0.8675
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 0.4909 train_roc: 0.9802 train_ap: 0.9807 time: 1.3967s
INFO:root:Epoch: 0045 val_loss: 1.3398 val_roc: 0.8746 val_ap: 0.8735
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 0.4170 train_roc: 0.9857 train_ap: 0.9829 time: 1.5435s
INFO:root:Epoch: 0050 val_loss: 0.9917 val_roc: 0.8802 val_ap: 0.8829
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 0.4155 train_roc: 0.9875 train_ap: 0.9835 time: 1.5625s
INFO:root:Epoch: 0055 val_loss: 0.9232 val_roc: 0.8845 val_ap: 0.8889
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 0.4051 train_roc: 0.9863 train_ap: 0.9822 time: 1.5537s
INFO:root:Epoch: 0060 val_loss: 0.9322 val_roc: 0.8872 val_ap: 0.8920
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 0.4058 train_roc: 0.9869 train_ap: 0.9827 time: 1.5568s
INFO:root:Epoch: 0065 val_loss: 0.9790 val_roc: 0.8896 val_ap: 0.8948
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 0.4047 train_roc: 0.9873 train_ap: 0.9854 time: 1.6314s
INFO:root:Epoch: 0070 val_loss: 1.0249 val_roc: 0.8912 val_ap: 0.8968
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 0.3954 train_roc: 0.9868 train_ap: 0.9793 time: 1.6181s
INFO:root:Epoch: 0075 val_loss: 1.0162 val_roc: 0.8926 val_ap: 0.8981
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 0.3720 train_roc: 0.9914 train_ap: 0.9887 time: 1.5753s
INFO:root:Epoch: 0080 val_loss: 0.9795 val_roc: 0.8948 val_ap: 0.9008
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 0.3706 train_roc: 0.9911 train_ap: 0.9890 time: 1.6144s
INFO:root:Epoch: 0085 val_loss: 0.9778 val_roc: 0.8968 val_ap: 0.9030
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 0.3876 train_roc: 0.9882 train_ap: 0.9825 time: 1.5973s
INFO:root:Epoch: 0090 val_loss: 0.9803 val_roc: 0.8984 val_ap: 0.9045
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 0.3736 train_roc: 0.9916 train_ap: 0.9887 time: 1.6064s
INFO:root:Epoch: 0095 val_loss: 0.9682 val_roc: 0.8998 val_ap: 0.9062
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.3574 train_roc: 0.9917 train_ap: 0.9878 time: 1.5987s
INFO:root:Epoch: 0100 val_loss: 0.9196 val_roc: 0.9017 val_ap: 0.9082
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.3775 train_roc: 0.9893 train_ap: 0.9834 time: 1.5491s
INFO:root:Epoch: 0105 val_loss: 0.9128 val_roc: 0.9029 val_ap: 0.9097
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.3575 train_roc: 0.9923 train_ap: 0.9880 time: 1.6351s
INFO:root:Epoch: 0110 val_loss: 0.9021 val_roc: 0.9038 val_ap: 0.9102
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 0.3766 train_roc: 0.9925 train_ap: 0.9897 time: 1.5754s
INFO:root:Epoch: 0115 val_loss: 0.8880 val_roc: 0.9043 val_ap: 0.9107
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.3413 train_roc: 0.9930 train_ap: 0.9891 time: 1.6338s
INFO:root:Epoch: 0120 val_loss: 0.9001 val_roc: 0.9050 val_ap: 0.9107
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.3640 train_roc: 0.9910 train_ap: 0.9855 time: 1.6412s
INFO:root:Epoch: 0125 val_loss: 0.9152 val_roc: 0.9056 val_ap: 0.9108
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.3488 train_roc: 0.9941 train_ap: 0.9929 time: 1.5453s
INFO:root:Epoch: 0130 val_loss: 0.8952 val_roc: 0.9065 val_ap: 0.9111
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.3664 train_roc: 0.9921 train_ap: 0.9883 time: 1.5403s
INFO:root:Epoch: 0135 val_loss: 0.8561 val_roc: 0.9062 val_ap: 0.9107
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.3376 train_roc: 0.9942 train_ap: 0.9920 time: 1.5415s
INFO:root:Epoch: 0140 val_loss: 0.8642 val_roc: 0.9066 val_ap: 0.9104
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.3500 train_roc: 0.9926 train_ap: 0.9880 time: 1.4536s
INFO:root:Epoch: 0145 val_loss: 0.8831 val_roc: 0.9070 val_ap: 0.9101
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.3737 train_roc: 0.9906 train_ap: 0.9864 time: 0.6466s
INFO:root:Epoch: 0150 val_loss: 0.9265 val_roc: 0.9075 val_ap: 0.9103
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.3517 train_roc: 0.9934 train_ap: 0.9912 time: 1.5795s
INFO:root:Epoch: 0155 val_loss: 0.9153 val_roc: 0.9072 val_ap: 0.9108
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.3536 train_roc: 0.9932 train_ap: 0.9900 time: 1.5739s
INFO:root:Epoch: 0160 val_loss: 0.9085 val_roc: 0.9064 val_ap: 0.9099
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.3619 train_roc: 0.9931 train_ap: 0.9894 time: 1.6369s
INFO:root:Epoch: 0165 val_loss: 0.9044 val_roc: 0.9064 val_ap: 0.9097
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.3478 train_roc: 0.9925 train_ap: 0.9904 time: 1.5308s
INFO:root:Epoch: 0170 val_loss: 0.8977 val_roc: 0.9071 val_ap: 0.9106
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.3441 train_roc: 0.9932 train_ap: 0.9899 time: 1.6287s
INFO:root:Epoch: 0175 val_loss: 0.9215 val_roc: 0.9070 val_ap: 0.9102
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.3369 train_roc: 0.9939 train_ap: 0.9901 time: 1.5858s
INFO:root:Epoch: 0180 val_loss: 0.8840 val_roc: 0.9066 val_ap: 0.9101
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.3496 train_roc: 0.9936 train_ap: 0.9895 time: 1.6139s
INFO:root:Epoch: 0185 val_loss: 0.8682 val_roc: 0.9074 val_ap: 0.9108
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.3316 train_roc: 0.9935 train_ap: 0.9893 time: 1.5628s
INFO:root:Epoch: 0190 val_loss: 0.8746 val_roc: 0.9082 val_ap: 0.9120
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.3478 train_roc: 0.9943 train_ap: 0.9913 time: 1.5761s
INFO:root:Epoch: 0195 val_loss: 0.8797 val_roc: 0.9095 val_ap: 0.9127
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.3462 train_roc: 0.9940 train_ap: 0.9911 time: 1.5532s
INFO:root:Epoch: 0200 val_loss: 0.8686 val_roc: 0.9102 val_ap: 0.9127
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.3364 train_roc: 0.9931 train_ap: 0.9884 time: 1.5673s
INFO:root:Epoch: 0205 val_loss: 0.9091 val_roc: 0.9099 val_ap: 0.9115
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.3439 train_roc: 0.9938 train_ap: 0.9916 time: 1.4523s
INFO:root:Epoch: 0210 val_loss: 0.9249 val_roc: 0.9093 val_ap: 0.9104
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.3320 train_roc: 0.9939 train_ap: 0.9912 time: 1.5718s
INFO:root:Epoch: 0215 val_loss: 0.9459 val_roc: 0.9089 val_ap: 0.9098
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.3254 train_roc: 0.9945 train_ap: 0.9907 time: 1.6327s
INFO:root:Epoch: 0220 val_loss: 0.9182 val_roc: 0.9076 val_ap: 0.9091
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.3339 train_roc: 0.9932 train_ap: 0.9878 time: 1.5699s
INFO:root:Epoch: 0225 val_loss: 0.8725 val_roc: 0.9065 val_ap: 0.9084
INFO:root:Epoch: 0230 lr: 0.01 train_loss: 0.3273 train_roc: 0.9950 train_ap: 0.9927 time: 1.5806s
INFO:root:Epoch: 0230 val_loss: 0.8934 val_roc: 0.9064 val_ap: 0.9087
INFO:root:Epoch: 0235 lr: 0.01 train_loss: 0.3297 train_roc: 0.9952 train_ap: 0.9946 time: 1.5441s
INFO:root:Epoch: 0235 val_loss: 0.8929 val_roc: 0.9064 val_ap: 0.9087
INFO:root:Epoch: 0240 lr: 0.01 train_loss: 0.3288 train_roc: 0.9944 train_ap: 0.9921 time: 1.4890s
INFO:root:Epoch: 0240 val_loss: 0.8585 val_roc: 0.9055 val_ap: 0.9076
INFO:root:Epoch: 0245 lr: 0.01 train_loss: 0.3301 train_roc: 0.9952 train_ap: 0.9938 time: 1.6002s
INFO:root:Epoch: 0245 val_loss: 0.8307 val_roc: 0.9046 val_ap: 0.9063
INFO:root:Epoch: 0250 lr: 0.01 train_loss: 0.3607 train_roc: 0.9944 train_ap: 0.9916 time: 1.5267s
INFO:root:Epoch: 0250 val_loss: 0.8696 val_roc: 0.9060 val_ap: 0.9064
INFO:root:Epoch: 0255 lr: 0.01 train_loss: 0.3404 train_roc: 0.9942 train_ap: 0.9922 time: 1.5619s
INFO:root:Epoch: 0255 val_loss: 0.9640 val_roc: 0.9060 val_ap: 0.9045
INFO:root:Epoch: 0260 lr: 0.01 train_loss: 0.3324 train_roc: 0.9937 train_ap: 0.9904 time: 1.6079s
INFO:root:Epoch: 0260 val_loss: 1.0063 val_roc: 0.9042 val_ap: 0.9020
INFO:root:Epoch: 0265 lr: 0.01 train_loss: 0.3195 train_roc: 0.9956 train_ap: 0.9941 time: 1.5636s
INFO:root:Epoch: 0265 val_loss: 0.9215 val_roc: 0.9033 val_ap: 0.9020
INFO:root:Epoch: 0270 lr: 0.01 train_loss: 0.3446 train_roc: 0.9931 train_ap: 0.9901 time: 1.5197s
INFO:root:Epoch: 0270 val_loss: 0.8525 val_roc: 0.9018 val_ap: 0.9014
INFO:root:Epoch: 0275 lr: 0.01 train_loss: 0.3518 train_roc: 0.9951 train_ap: 0.9923 time: 1.5202s
INFO:root:Epoch: 0275 val_loss: 0.8973 val_roc: 0.9014 val_ap: 0.9010
INFO:root:Epoch: 0280 lr: 0.01 train_loss: 0.3394 train_roc: 0.9941 train_ap: 0.9917 time: 1.5098s
INFO:root:Epoch: 0280 val_loss: 0.9604 val_roc: 0.9030 val_ap: 0.9033
INFO:root:Epoch: 0285 lr: 0.01 train_loss: 0.3498 train_roc: 0.9944 train_ap: 0.9901 time: 1.5739s
INFO:root:Epoch: 0285 val_loss: 0.9564 val_roc: 0.9029 val_ap: 0.9039
INFO:root:Epoch: 0290 lr: 0.01 train_loss: 0.3264 train_roc: 0.9940 train_ap: 0.9923 time: 1.4904s
INFO:root:Epoch: 0290 val_loss: 0.9332 val_roc: 0.9027 val_ap: 0.9032
INFO:root:Epoch: 0295 lr: 0.01 train_loss: 0.3242 train_roc: 0.9948 train_ap: 0.9927 time: 1.5255s
INFO:root:Epoch: 0295 val_loss: 0.8839 val_roc: 0.9015 val_ap: 0.9022
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 603.1522s
INFO:root:Val set results: val_loss: 0.8649 val_roc: 0.9101 val_ap: 0.9130
INFO:root:Test set results: test_loss: 0.7690 test_roc: 0.9345 test_ap: 0.9346
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/lp/2021_4_22/3
