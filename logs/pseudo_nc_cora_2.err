INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:Num classes: 7
INFO:root:NCModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(in_features=1434, out_features=16, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (agg): HypAgg(c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
        (hyp_act): HypAct(c_in=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>), c_out=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>))
      )
    )
  )
  (decoder): LinearDecoder(
    in_features=16, out_features=7, bias=1, c=tensor([-1.], device='cuda:0', grad_fn=<CopyBackwards>)
    (cls): Linear(
      (linear): Linear(in_features=16, out_features=7, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 23079
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.9519 train_acc: 0.1786 train_f1: 0.1786 time: 1.1215s
INFO:root:Epoch: 0005 val_loss: 1.9367 val_acc: 0.1340 val_f1: 0.1340
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.9190 train_acc: 0.1857 train_f1: 0.1857 time: 0.9813s
INFO:root:Epoch: 0010 val_loss: 1.9380 val_acc: 0.1580 val_f1: 0.1580
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.8887 train_acc: 0.3286 train_f1: 0.3286 time: 1.1017s
INFO:root:Epoch: 0015 val_loss: 1.9316 val_acc: 0.2160 val_f1: 0.2160
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.8660 train_acc: 0.2929 train_f1: 0.2929 time: 1.0638s
INFO:root:Epoch: 0020 val_loss: 1.9030 val_acc: 0.3580 val_f1: 0.3580
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.8180 train_acc: 0.4286 train_f1: 0.4286 time: 1.0052s
INFO:root:Epoch: 0025 val_loss: 1.8646 val_acc: 0.4960 val_f1: 0.4960
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 1.7648 train_acc: 0.4857 train_f1: 0.4857 time: 1.1239s
INFO:root:Epoch: 0030 val_loss: 1.8416 val_acc: 0.5240 val_f1: 0.5240
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 1.6800 train_acc: 0.5357 train_f1: 0.5357 time: 1.0178s
INFO:root:Epoch: 0035 val_loss: 1.8152 val_acc: 0.4520 val_f1: 0.4520
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 1.5744 train_acc: 0.6286 train_f1: 0.6286 time: 1.1169s
INFO:root:Epoch: 0040 val_loss: 1.7618 val_acc: 0.5520 val_f1: 0.5520
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 1.5656 train_acc: 0.5429 train_f1: 0.5429 time: 0.9303s
INFO:root:Epoch: 0045 val_loss: 1.7062 val_acc: 0.6120 val_f1: 0.6120
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 1.4542 train_acc: 0.5714 train_f1: 0.5714 time: 1.1235s
INFO:root:Epoch: 0050 val_loss: 1.6764 val_acc: 0.6040 val_f1: 0.6040
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 1.3220 train_acc: 0.6214 train_f1: 0.6214 time: 0.9933s
INFO:root:Epoch: 0055 val_loss: 1.6203 val_acc: 0.6800 val_f1: 0.6800
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 1.3487 train_acc: 0.5786 train_f1: 0.5786 time: 1.1429s
INFO:root:Epoch: 0060 val_loss: 1.5465 val_acc: 0.7400 val_f1: 0.7400
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 1.2487 train_acc: 0.6071 train_f1: 0.6071 time: 1.0059s
INFO:root:Epoch: 0065 val_loss: 1.5011 val_acc: 0.7400 val_f1: 0.7400
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 1.2542 train_acc: 0.5357 train_f1: 0.5357 time: 1.0306s
INFO:root:Epoch: 0070 val_loss: 1.4659 val_acc: 0.7420 val_f1: 0.7420
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 1.1944 train_acc: 0.6000 train_f1: 0.6000 time: 1.0113s
INFO:root:Epoch: 0075 val_loss: 1.4152 val_acc: 0.7500 val_f1: 0.7500
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 1.0965 train_acc: 0.5929 train_f1: 0.5929 time: 1.0003s
INFO:root:Epoch: 0080 val_loss: 1.3790 val_acc: 0.7480 val_f1: 0.7480
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 1.0806 train_acc: 0.6071 train_f1: 0.6071 time: 1.1914s
INFO:root:Epoch: 0085 val_loss: 1.3461 val_acc: 0.7360 val_f1: 0.7360
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 1.0589 train_acc: 0.6214 train_f1: 0.6214 time: 1.0020s
INFO:root:Epoch: 0090 val_loss: 1.2921 val_acc: 0.7520 val_f1: 0.7520
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 0.9769 train_acc: 0.6714 train_f1: 0.6714 time: 1.0524s
INFO:root:Epoch: 0095 val_loss: 1.2644 val_acc: 0.7500 val_f1: 0.7500
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.8993 train_acc: 0.6429 train_f1: 0.6429 time: 1.0341s
INFO:root:Epoch: 0100 val_loss: 1.2304 val_acc: 0.7420 val_f1: 0.7420
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.8005 train_acc: 0.6643 train_f1: 0.6643 time: 1.2133s
INFO:root:Epoch: 0105 val_loss: 1.1971 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.9232 train_acc: 0.6500 train_f1: 0.6500 time: 0.8508s
INFO:root:Epoch: 0110 val_loss: 1.1673 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 0.9980 train_acc: 0.5786 train_f1: 0.5786 time: 1.1080s
INFO:root:Epoch: 0115 val_loss: 1.1464 val_acc: 0.7560 val_f1: 0.7560
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.9720 train_acc: 0.5786 train_f1: 0.5786 time: 1.0165s
INFO:root:Epoch: 0120 val_loss: 1.1344 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.8793 train_acc: 0.6500 train_f1: 0.6500 time: 0.9693s
INFO:root:Epoch: 0125 val_loss: 1.1131 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.7608 train_acc: 0.6714 train_f1: 0.6714 time: 1.1211s
INFO:root:Epoch: 0130 val_loss: 1.0812 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.8911 train_acc: 0.6143 train_f1: 0.6143 time: 0.9683s
INFO:root:Epoch: 0135 val_loss: 1.0785 val_acc: 0.7720 val_f1: 0.7720
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.7014 train_acc: 0.6929 train_f1: 0.6929 time: 1.2320s
INFO:root:Epoch: 0140 val_loss: 1.0738 val_acc: 0.7620 val_f1: 0.7620
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.8166 train_acc: 0.6786 train_f1: 0.6786 time: 1.1196s
INFO:root:Epoch: 0145 val_loss: 1.0475 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.8790 train_acc: 0.6000 train_f1: 0.6000 time: 1.0017s
INFO:root:Epoch: 0150 val_loss: 1.0266 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.7532 train_acc: 0.6643 train_f1: 0.6643 time: 1.2393s
INFO:root:Epoch: 0155 val_loss: 1.0250 val_acc: 0.7660 val_f1: 0.7660
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.7508 train_acc: 0.6786 train_f1: 0.6786 time: 1.1876s
INFO:root:Epoch: 0160 val_loss: 1.0288 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.8175 train_acc: 0.6429 train_f1: 0.6429 time: 1.0042s
INFO:root:Epoch: 0165 val_loss: 1.0203 val_acc: 0.7680 val_f1: 0.7680
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.7987 train_acc: 0.6786 train_f1: 0.6786 time: 1.1246s
INFO:root:Epoch: 0170 val_loss: 1.0000 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.7719 train_acc: 0.6214 train_f1: 0.6214 time: 0.8765s
INFO:root:Epoch: 0175 val_loss: 0.9917 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.8848 train_acc: 0.5929 train_f1: 0.5929 time: 1.0859s
INFO:root:Epoch: 0180 val_loss: 0.9947 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.6570 train_acc: 0.7000 train_f1: 0.7000 time: 1.1146s
INFO:root:Epoch: 0185 val_loss: 0.9889 val_acc: 0.7580 val_f1: 0.7580
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.7317 train_acc: 0.6571 train_f1: 0.6571 time: 1.0135s
INFO:root:Epoch: 0190 val_loss: 0.9606 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.6816 train_acc: 0.7071 train_f1: 0.7071 time: 1.0129s
INFO:root:Epoch: 0195 val_loss: 0.9489 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.8091 train_acc: 0.6000 train_f1: 0.6000 time: 1.1241s
INFO:root:Epoch: 0200 val_loss: 0.9543 val_acc: 0.7640 val_f1: 0.7640
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.7259 train_acc: 0.7071 train_f1: 0.7071 time: 1.1482s
INFO:root:Epoch: 0205 val_loss: 0.9645 val_acc: 0.7540 val_f1: 0.7540
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.6774 train_acc: 0.6786 train_f1: 0.6786 time: 1.1591s
INFO:root:Epoch: 0210 val_loss: 0.9505 val_acc: 0.7680 val_f1: 0.7680
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.7598 train_acc: 0.6571 train_f1: 0.6571 time: 1.1168s
INFO:root:Epoch: 0215 val_loss: 0.9460 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.6807 train_acc: 0.6929 train_f1: 0.6929 time: 1.2848s
INFO:root:Epoch: 0220 val_loss: 0.9602 val_acc: 0.7440 val_f1: 0.7440
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.7759 train_acc: 0.6500 train_f1: 0.6500 time: 1.1635s
INFO:root:Epoch: 0225 val_loss: 0.9415 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0230 lr: 0.01 train_loss: 0.7963 train_acc: 0.6214 train_f1: 0.6214 time: 1.0008s
INFO:root:Epoch: 0230 val_loss: 0.9383 val_acc: 0.7600 val_f1: 0.7600
INFO:root:Epoch: 0235 lr: 0.01 train_loss: 0.7810 train_acc: 0.6000 train_f1: 0.6000 time: 1.0958s
INFO:root:Epoch: 0235 val_loss: 0.9495 val_acc: 0.7700 val_f1: 0.7700
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 318.9894s
INFO:root:Val set results: val_loss: 1.0785 val_acc: 0.7720 val_f1: 0.7720
INFO:root:Test set results: test_loss: 1.0547 test_acc: 0.7790 test_f1: 0.7790
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/nc/2021_4_22/23
